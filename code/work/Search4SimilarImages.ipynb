{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "12d2452e",
   "metadata": {},
   "source": [
    "This work is inspired blog post of Maciej D. Korzec https://towardsdatascience.com/recommending-similar-images-using-pytorch-da019282770c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "57a448f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from PIL import Image\n",
    "from torchvision import transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "62f48a1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# needed input dimensions for the CNN\n",
    "inputDim = (224,224)\n",
    "# directories :\\Users\\telmi\\Documents\\dhh23\\EarlyModernReuse\\early_modern_data-main\\data\\all_images\\cropped\\illustration\n",
    "inputDir = \"C:/Users/telmi/Documents/dhh23/EarlyModernReuse/early_modern_data-main/data/all_images/cropped/illustration\" #\"/scratch/project_2005488/DHH23/early_modern_samples/similarity\"\n",
    "inputDirCNN = \"C:/Users/telmi/Documents/dhh23/EarlyModernReuse/data\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2e045a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(inputDirCNN, exist_ok = True)\n",
    "\n",
    "transformationForCNNInput = transforms.Compose([transforms.Resize(inputDim)])\n",
    "\n",
    "for imageName in os.listdir(inputDir):\n",
    "    I = Image.open(os.path.join(inputDir, imageName))\n",
    "    newI = transformationForCNNInput(I)\n",
    "\n",
    "    # copy the rotation information metadata from original image and save, else your transformed images may be rotated\n",
    "    # exif = I.info['exif']\n",
    "    newI.save(os.path.join(inputDirCNN, imageName))\n",
    "    \n",
    "    newI.close()\n",
    "    I.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f6447a2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from tqdm import tqdm\n",
    "from torchvision import models\n",
    "import json\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bacbb47c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converting images to feature vectors:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 72%|███████████████████████████████████████████████████████▋                     | 9504/13152 [21:09<09:24,  6.46it/s]"
     ]
    }
   ],
   "source": [
    "# for this prototype we use no gpu, cuda= False and as model resnet18 to obtain feature vectors\n",
    "\n",
    "class Img2VecResnet18():\n",
    "    def __init__(self):\n",
    "        \n",
    "        self.device = torch.device(\"cpu\")\n",
    "        self.numberFeatures = 512\n",
    "        self.modelName = \"resnet-18\"\n",
    "        self.model, self.featureLayer = self.getFeatureLayer()\n",
    "        self.model = self.model.to(self.device)\n",
    "        self.model.eval()\n",
    "        self.toTensor = transforms.ToTensor()\n",
    "        \n",
    "        # normalize the resized images as expected by resnet18\n",
    "        # [0.485, 0.456, 0.406] --> normalized mean value of ImageNet, [0.229, 0.224, 0.225] std of ImageNet\n",
    "        self.normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "        \n",
    "    def getVec(self, img):\n",
    "        image = self.normalize(self.toTensor(img)).unsqueeze(0).to(self.device)\n",
    "        embedding = torch.zeros(1, self.numberFeatures, 1, 1)\n",
    "\n",
    "        def copyData(m, i, o): embedding.copy_(o.data)\n",
    "\n",
    "        h = self.featureLayer.register_forward_hook(copyData)\n",
    "        self.model(image)\n",
    "        h.remove()\n",
    "\n",
    "        return embedding.numpy()[0, :, 0, 0]\n",
    "\n",
    "    def getFeatureLayer(self):\n",
    "        \n",
    "        cnnModel = models.resnet18(pretrained=True)\n",
    "        layer = cnnModel._modules.get('avgpool')\n",
    "        self.layer_output_size = 512\n",
    "        \n",
    "        return cnnModel, layer\n",
    "        \n",
    "\n",
    "# generate vectors for all the images in the set\n",
    "img2vec = Img2VecResnet18() \n",
    "\n",
    "DATA_FILENAME = inputDirCNN+\"/vectors/vectors.json\"\n",
    "with open(DATA_FILENAME, mode='w', encoding='utf-8') as feedsjson:\n",
    "    #feeds = json.load(feedsjson)\n",
    "    entry = {}\n",
    "    entry[\"sth\"] = 0\n",
    "    #entry['name'] = args.name\n",
    "    #entry['url'] = args.url\n",
    "   # entry_dump=\n",
    "    json.dump(entry,feedsjson)\n",
    "\n",
    "allVectors = {}\n",
    "print(\"Converting images to feature vectors:\")\n",
    "for image in tqdm(os.listdir(inputDirCNN)):\n",
    "    I = Image.open(os.path.join(inputDirCNN, image)).convert(\"RGB\")\n",
    "    vec = img2vec.getVec(I)\n",
    "    allVectors[image] = vec\n",
    "    with open(DATA_FILENAME) as f:\n",
    "        data_temp = json.load(f)\n",
    "\n",
    "    #data_temp.update(allVectors)\n",
    "    temp= {image:vec}\n",
    "    data_temp.update(temp)\n",
    "    #with open(DATA_FILENAME, 'w') as f:\n",
    "    #    json.dump(data_temp, f)\n",
    "    filename=  inputDirCNN+\"/vectors/\" + image.split(\".\")[0]+ \".txt\"\n",
    "    np.savetxt(filename, vec, fmt='%d')\n",
    "    I.close() \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "fcbf7a4a",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'allVectors' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[23], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28mlen\u001b[39m(allVectors)\n\u001b[0;32m      2\u001b[0m fn\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mC:/Users/telmi/Documents/dhh23/EarlyModernReuse/vector_dict.json\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m      3\u001b[0m vectors_dict\u001b[38;5;241m=\u001b[39m {k:v\u001b[38;5;241m.\u001b[39mtolist() \u001b[38;5;28;01mfor\u001b[39;00m k,v \u001b[38;5;129;01min\u001b[39;00m allVectors\u001b[38;5;241m.\u001b[39mitems()}\n",
      "\u001b[1;31mNameError\u001b[0m: name 'allVectors' is not defined"
     ]
    }
   ],
   "source": [
    "len(allVectors)\n",
    "fn= \"C:/Users/telmi/Documents/dhh23/EarlyModernReuse/vector_dict.json\"\n",
    "vectors_dict= {k:v.tolist() for k,v in allVectors.items()}\n",
    "\n",
    "#with open(fn, 'w') as f:\n",
    "    #json.dump(vectors_dict, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d70bda84",
   "metadata": {},
   "outputs": [],
   "source": [
    "# now let us define a function that calculates the cosine similarity entries in the similarity matrix\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42b2f6b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read the vectors in\n",
    "fn= \"C:/Users/telmi/Documents/dhh23/EarlyModernReuse/vector_dict.json\"\n",
    "\n",
    "with open(fn, 'r') as f:\n",
    "    vectors_dict= json.load(f)\n",
    "    \n",
    "len(vectors_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac7a1ac4",
   "metadata": {},
   "outputs": [],
   "source": [
    "allVectors= {k:np.array(v) for k,v in vectors_dict.items()}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce848207",
   "metadata": {},
   "outputs": [],
   "source": [
    "# the key is the image name\n",
    "print(list(allVectors.keys())[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "beba6f60",
   "metadata": {},
   "outputs": [],
   "source": [
    "# a subset\n",
    "someKeys= list(allVectors.keys())[:500]\n",
    "someValues=list(allVectors.values())[:500]\n",
    "notAllVectors = {k:v for k,v in zip(someKeys,someValues) }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "78f72800",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['8vo', '4to', '2fo', nan, '12mo', '16mo', '32mo', '8long', '18mo',\n",
       "       '24mo', '12long'], dtype=object)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read in the necessary data based on metadata criteria\n",
    "\n",
    "import glob\n",
    "import pandas as pd\n",
    "path=\"C:/Users/telmi/Documents/dhh23/EarlyModernReuse/vectors/\"\n",
    "mynp= glob.glob(path+\"*\")\n",
    "\n",
    "# read in metadata\n",
    "dpath= \"C:/Users/telmi/Documents/dhh23/EarlyModernReuse/early_modern_data-main/\"\n",
    "\n",
    "# C:\\Users\\telmi\\Documents\\dhh23\\reuseportfolio\n",
    "meta = dpath + \"metadata.csv\"\n",
    "clip= dpath + \"clip_classification.csv\"\n",
    "\n",
    "meta = pd.read_csv(meta, dtype={\"page_id\":str, \"ecco_id\":str})\n",
    "meta.gatherings.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "6d98bd0d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13151"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(mynp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "62de8ce5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "95346 95346\n",
      "11896 13151\n"
     ]
    }
   ],
   "source": [
    "# load in the wanted vectors\n",
    "meta_=meta[meta[\"gatherings\"].isin([\"12mo\",\"8vo\",\"4to\",\"2fo\"])]\n",
    "print(len(meta_), meta_[\"page_id\"].nunique())\n",
    "\n",
    "\n",
    "# wanted files\n",
    "wlist=[]\n",
    "filteredVectors={}\n",
    "err=[]\n",
    "for pic in list(mynp):\n",
    "    pic_id = pic.split(\".json\")[-1]\n",
    "    page_id = pic_id.split(\"_\")[0]\n",
    "    \n",
    "    try:\n",
    "        if page_id in list(meta_[\"page_id\"]):\n",
    "            wlist.append(pic)\n",
    "            filteredVectors[pic_id]=np.loadtxt(pic)\n",
    "    except:\n",
    "        err.append(pic)\n",
    "print(len(wlist), len (mynp))      \n",
    "#filteredVectors[pic_id]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "290848c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def getSimilarityMatrix(vectors):\n",
    "    v = np.array(list(vectors.values())).T\n",
    "    sim = np.inner(v.T, v.T) / ((np.linalg.norm(v, axis=0).reshape(-1,1)) * ((np.linalg.norm(v, axis=0).reshape(-1,1)).T))\n",
    "    keys = list(vectors.keys())\n",
    "    matrix = pd.DataFrame(sim, columns = keys, index = keys)\n",
    "    \n",
    "    return matrix\n",
    "        \n",
    "similarityMatrix = getSimilarityMatrix(filteredVectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bc9ab32",
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy.testing import assert_almost_equal\n",
    "import pickle\n",
    "\n",
    "k = 5 # the number of top similar images to be stored\n",
    "\n",
    "similarNames = pd.DataFrame(index = similarityMatrix.index, columns = range(k))\n",
    "similarValues = pd.DataFrame(index = similarityMatrix.index, columns = range(k))\n",
    "\n",
    "for j in tqdm(range(similarityMatrix.shape[0])):\n",
    "    kSimilar = similarityMatrix.iloc[j, :].sort_values(ascending = False).head(k)\n",
    "    similarNames.iloc[j, :] = list(kSimilar.index)\n",
    "    similarValues.iloc[j, :] = kSimilar.values\n",
    "similarNames_path = \"/scratch/project_2005488/DHH23/model/similarNames.pkl\"\n",
    "similarValues_path = \"/scratch/project_2005488/DHH23/model/similarValues.pkl\"\n",
    "similarNames.to_pickle(similarNames_path)\n",
    "similarValues.to_pickle(similarValues_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fadf333",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the vectors\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38c2c7c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# open a file, where you stored the pickled data\n",
    "file = open(similarNames_path, 'rb')\n",
    "simNames = pickle.load(file)\n",
    "file.close()\n",
    "\n",
    "file = open(similarValues_path, 'rb')\n",
    "simValues = pickle.load(file)\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e0db8a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def setAxes(ax, image, query = False, **kwargs):\n",
    "    value = kwargs.get(\"value\", None)\n",
    "    if query:\n",
    "        ax.set_xlabel(\"Query Image\\n{0}\".format(image), fontsize = 8)\n",
    "    else:\n",
    "        ax.set_xlabel(\"Similarity value {1:1.3f}\\n{0}\".format( image,  value), fontsize = 8)\n",
    "    ax.set_xticks([])\n",
    "    ax.set_yticks([])\n",
    "    \n",
    "def getSimilarImages(image, simNames, simVals):\n",
    "    if image in set(simNames.index):\n",
    "        imgs = list(simNames.loc[image, :])\n",
    "        vals = list(simVals.loc[image, :])\n",
    "        if image in imgs:\n",
    "            assert_almost_equal(max(vals), 1, decimal = 5)\n",
    "            imgs.remove(image)\n",
    "            vals.remove(max(vals))\n",
    "        return imgs, vals\n",
    "    else:\n",
    "        print(\"'{}' Unknown image\".format(image))\n",
    "        \n",
    "def plotSimilarImages(image, simiarNames, similarValues):\n",
    "    simImages, simValues = getSimilarImages(image, similarNames, similarValues)\n",
    "    fig = plt.figure(figsize=(10, 20))\n",
    "    \n",
    "    # now plot the  most simliar images\n",
    "    for j in range(0, numCol*numRow):\n",
    "        ax = []\n",
    "        if j == 0:\n",
    "            img = Image.open(os.path.join(inputDir, image))\n",
    "            ax = fig.add_subplot(numRow, numCol, 1)\n",
    "            setAxes(ax, image, query = True)\n",
    "        else:\n",
    "            img = Image.open(os.path.join(inputDir, simImages[j-1]))\n",
    "            ax.append(fig.add_subplot(numRow, numCol, j+1))\n",
    "            setAxes(ax[-1], simImages[j-1], value = simValues[j-1])\n",
    "        img = img.convert('RGB')\n",
    "        plt.imshow(img)\n",
    "        img.close()\n",
    "    \n",
    "    plt.show()\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "549a5065",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import random    \n",
    "# take three examples from the provided image set and plot\n",
    "folder_path = \"/scratch/project_2005488/DHH23/early_modern_samples/similarity\"\n",
    "numCol = 5\n",
    "numRow = 1\n",
    "num_files = 100\n",
    "all_files = os.listdir(folder_path)\n",
    "# Shuffle the list of files randomly\n",
    "random.shuffle(all_files)\n",
    "selected_files = all_files[:num_files]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "for image in selected_files:\n",
    "    plotSimilarImages(image, simNames, simValues)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f45ba621",
   "metadata": {},
   "outputs": [],
   "source": [
    "similarNames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56e4b785",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dhh",
   "language": "python",
   "name": "dhh"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
